{"cells":[{"cell_type":"code","execution_count":null,"id":"9f0cc6fb","metadata":{"id":"9f0cc6fb"},"outputs":[],"source":["\"\"\"Code for defining and loading the models we trained.\"\"\"\n","import os\n","import torch\n","import torchvision\n","import time\n","import copy\n","\n","#Eval imports\n","from torchvision import transforms, datasets\n","from torch.autograd import Variable\n","from torchvision.utils import save_image\n","import tqdm\n","import argparse\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","from sklearn.metrics import (f1_score, balanced_accuracy_score,\n","   classification_report, confusion_matrix, roc_curve, auc)\n","import torch.optim as optim\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b006e624","metadata":{"id":"b006e624"},"outputs":[],"source":["data_dir = \"<dataset_paths>\"\n","\n","# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","model_name = \"DeepDerm\"\n","\n","# Number of classes in the dataset\n","num_classes = 2\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 32\n","\n","# Number of epochs to train for\n","num_epochs = 200\n","\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = True\n","device = \"cpu\""]},{"cell_type":"code","execution_count":null,"id":"d096a392","metadata":{"id":"d096a392"},"outputs":[],"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"id":"49f61d61","metadata":{"id":"49f61d61"},"outputs":[],"source":["def mixup_data(x, y, alpha=0.2):\n","    '''Returns mixed inputs, pairs of targets, and lambda'''\n","    lam = np.random.beta(alpha, alpha)\n","    batch_size = x.size()[0]\n","    index = torch.randperm(batch_size)\n","    mixed_x = lam * x + (1 - lam) * x[index, :]\n","    y_a, y_b = y, y[index]\n","    return mixed_x, y_a, y_b, lam\n"]},{"cell_type":"code","execution_count":null,"id":"ba433f24","metadata":{"id":"ba433f24"},"outputs":[],"source":["def mixup_criterion(criterion, pred, y_a, y_b, lam):\n","    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"]},{"cell_type":"code","execution_count":null,"id":"210684e6","metadata":{"id":"210684e6"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception= True):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                #Line added on Oct 23, 2022\n","                inputs, labels_a, labels_b, lam =mixup_data(inputs, labels)\n","                #Line added on Oct 23, 2022\n","                inputs, labels_a, labels_b = map(Variable,(inputs, labels_a, labels_b))\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        # outputs, aux_outputs = model(inputs)\n","                        # loss1 = criterion(outputs, labels)\n","                        # loss2 = criterion(aux_outputs, labels)\n","                        #Line added on Oct 23, 2022\n","                        outputs,aux_outputs = model(inputs)\n","                        loss = mixup_criterion(criterion,outputs, labels_a, labels_b,lam)\n","                        #loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"]},{"cell_type":"code","execution_count":null,"id":"3c3ff3bb","metadata":{"id":"3c3ff3bb"},"outputs":[],"source":["\n","# google drive paths to our models\n","MODEL_WEB_PATHS = {\n","# base form of models trained on skin data\n","'HAM10000':'https://drive.google.com/uc?id=1ToT8ifJ5lcWh8Ix19ifWlMcMz9UZXcmo',\n","'DeepDerm':'https://drive.google.com/uc?id=1OLt11htu9bMPgsE33vZuDiU5Xe4UqKVJ',\n","\n","# robust training algorithms\n","'GroupDRO':'https://drive.google.com/uc?id=193ippDUYpMaOaEyLjd1DNsOiW0aRXL75',\n","'CORAL':   'https://drive.google.com/uc?id=18rMU0nRd4LiHN9WkXoDROJ2o2sG1_GD8',\n","'CDANN':   'https://drive.google.com/uc?id=1PvvgQVqcrth840bFZ3ddLdVSL7NkxiRK',\n","}\n","\n","# thresholds determined by maximizing F1-score on the test split of the train\n","#   dataset for the given algorithm\n","MODEL_THRESHOLDS = {\n","    'HAM10000':0.733,\n","    'DeepDerm':0.687,\n","    # robust training algorithms\n","    'GroupDRO':0.980,\n","    'CORAL':0.990,\n","    'CDANN':0.980,\n","}\n","\n","def load_model(model_name, save_dir=\"DDI-models\", download=True, fineTuning = False):\n","    \"\"\"Load the model and download if necessary. Saves model to provided save\n","    directory.\"\"\"\n","    os.makedirs(save_dir, exist_ok=True)\n","    model_path = os.path.join(save_dir, f\"{model_name.lower()}.pth\")\n","    if not os.path.exists(model_path):\n","        if not download:\n","            raise Exception(\"Model not downloaded and download option not\"\\\n","                            \" enabled.\")\n","        else:\n","            # Requires installation of gdown (pip install gdown)\n","            import gdown\n","            gdown.download(MODEL_WEB_PATHS[model_name], model_path)\n","    model = torchvision.models.inception_v3(weights=True, init_weights=False,transform_input=True)\n","\n","    if(fineTuning):\n","        set_parameter_requires_grad(model, feature_extract)\n","\n","    model.fc = torch.nn.Linear(2048, 2)\n","    model.AuxLogits.fc = torch.nn.Linear(768, 2)\n","    state_dict = torch.load(model_path)\n","    model.load_state_dict(state_dict)\n","    model._ddi_name = model_name\n","    model._ddi_threshold = MODEL_THRESHOLDS[model_name]\n","    model._ddi_web_path = MODEL_WEB_PATHS[model_name]\n","    return model\n","\n","#Following pasted from eval_model\n","\n","class ImageFolderWithPaths(datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method that dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns\n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # the image file path\n","        path = os.path.abspath(self.imgs[index][0])\n","        # make a new tuple that includes original and the path\n","        tuple_with_path = (original_tuple + (path,))\n","        return tuple_with_path\n","\n","def eval_model(model, image_dir, use_gpu=False, show_plot=False):\n","    \"\"\"Evaluate loaded model on provided image dataset. Assumes supplied image\n","    directory corresponds to `root` input for torchvision.datasets.ImageFolder\n","    class. Assumes the data is split into binary/malignant labels, as this is\n","    what our models are trained+evaluated on.\"\"\"\n","\n","    use_gpu = (use_gpu and torch.cuda.is_available())\n","    device = torch.device(\"cuda\") if use_gpu else torch.device(\"cpu\")\n","\n","    # load dataset\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    dataset = ImageFolderWithPaths(\n","                    image_dir,\n","                    transforms.Compose([\n","                        transforms.Resize(299),\n","                        transforms.CenterCrop(299),\n","                        transforms.ToTensor(),\n","                        normalize]))\n","    dataloader = torch.utils.data.DataLoader(\n","                    dataset,\n","                    batch_size=32, shuffle=False,\n","                    num_workers=0, pin_memory=use_gpu)\n","\n","    # prepare model for evaluation\n","    model.to(device).eval()\n","\n","    # log output for all images in dataset\n","    hat, star, all_paths = [], [], []\n","    for batch in tqdm.tqdm(enumerate(dataloader)):\n","        i, (images, target, paths) = batch\n","        images = images.to(device)\n","        target = target.to(device)\n","\n","        with torch.no_grad():\n","            output = model(images)\n","\n","        hat.append(output[:,1].detach().cpu().numpy())\n","        star.append(target.cpu().numpy())\n","        all_paths.append(paths)\n","\n","    hat = np.concatenate(hat)\n","    star = np.concatenate(star)\n","    all_paths = np.concatenate(all_paths)\n","    threshold = model._ddi_threshold\n","    m_name = model._ddi_name\n","    m_web_path = model._ddi_web_path\n","\n","    report = classification_report(star, (hat>threshold).astype(int),\n","        target_names=[\"benign\",\"malignant\"])\n","    cfm = confusion_matrix(y_true=star,y_pred=(hat>threshold).astype(int))\n","    fpr, tpr, _ = roc_curve(star, hat, pos_label=1,\n","                                sample_weight=None,\n","                                drop_intermediate=True)\n","    auc_est = auc(fpr, tpr)\n","\n","    if show_plot:\n","        _=plt.plot(fpr, tpr,\n","            color=\"blue\", linestyle=\"-\", linewidth=2,\n","            marker=\"o\", markersize=2,\n","            label=f\"AUC={auc_est:.3f}\")[0]\n","        plt.show()\n","        plt.close()\n","\n","    eval_results = {'predicted_labels':hat, # predicted labels by model\n","                    'true_labels':star,     # true labels\n","                    'images':all_paths,     # image paths\n","                    'report':report,        # sklearn classification report\n","                    'ROC_AUC':auc_est,      # ROC-AUC\n","                    'threshold':threshold,  # >= threshold ==> malignant\n","                    'model':m_name,         # model name\n","                    'web_path':m_web_path,  # web link to download model\n","                    'confusion_matrix':cfm\n","                    }\n","\n","    return eval_results"]},{"cell_type":"code","execution_count":null,"id":"49768cfa","metadata":{"id":"49768cfa","outputId":"33d6629b-1dbc-4012-ff0a-cd0deed6c209"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing Datasets and Dataloaders...\n"]}],"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","input_size = 299\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomRotation(degrees=20),\n","        transforms.RandomVerticalFlip(p=0.5),\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1),\n","        transforms.GaussianBlur(kernel_size=(5,9),sigma=(0.1,5)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n"]},{"cell_type":"code","execution_count":null,"id":"c7ed9ee6","metadata":{"id":"c7ed9ee6"},"outputs":[],"source":["# Send the model to GPU\n","model_ft = DeepDerm.to(device=\"cpu\")\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","# print(\"Params to learn:\")\n","# if feature_extract:\n","#     params_to_update = []\n","#     for name,param in model_ft.named_parameters():\n","#         if param.requires_grad == True:\n","#             params_to_update.append(param)\n","#             print(\"\\t\",name)\n","# else:\n","#     for name,param in model_ft.named_parameters():\n","#         if param.requires_grad == True:\n","#             print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(params_to_update, lr=0.05, weight_decay=0.0004)"]},{"cell_type":"code","execution_count":null,"id":"6ba68536","metadata":{"id":"6ba68536"},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","\n","# Train and evaluate\n","model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"]},{"cell_type":"code","execution_count":null,"id":"582046f4","metadata":{"id":"582046f4"},"outputs":[],"source":["STATE_DICT_SAVE_PATH = \"<model_path>.pth\"\n","MODEL_SAVE_PATH = \"<model_path>.pth\"\n","torch.save(model_ft.state_dict(),STATE_DICT_SAVE_PATH)\n","torch.save(model_ft,MODEL_SAVE_PATH)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"jupyter","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10 (default, Mar 13 2023, 10:26:41) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"d9a1b7669aa58b21281966e4dc3ffb192926acf0fd5c2d461a7d4be4b67001fb"}}},"nbformat":4,"nbformat_minor":5}
