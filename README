This repository contains code and experiment for the paper:

# Toward Fairness Across Skin Tones in Dermatological Image Processing

Abstract:
Skin cancer is a prevalent and concerning form of cancer, with an annual incidence rate estimated to be more than3 million cases in the US. In recent years, the field of medical image processing has made a remarkable progress in thedomain of skin cancer detection, surpassing the diagnostic capabilities of dermatologists in certain settings. However, it has been reported that the performance of these deeplearning detection models varies significantly across differ-ent skin tones (e.g., light versus dark), motivating the needfor fair and unbiased classification results. Here, we evaluate DeepDerm, a state-of-the-art skin cancer detectionmodel, specifically focusing on its performance across skintypes classified by the Fitzpatrick Skin Tones (FST). By analyzing the modelâ€™s accuracy and fairness, we observe no-table discrepancies in its performance across different FSTcategories. We propose a novel architecture that leverages finetuning, an ensemble architecture, and fairness-based resampling for supporting high accuracy and fairness inskin cancer detection. The proposed framework demonstrates promising outcomes, marking a significant stridetoward achieving fairness and accuracy in dermatological image processing.
